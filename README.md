# ONNX Runtime collection of tutorials

In this repo, you are going to find a collection of ONNX Runtime tutorials written in python with some modification in part of the code to benchmark performances between standard inference of other frameworks and ONNX Runtime inference engine.

 CPU is the hardware platform targeted. Exploited MLAS + Eigen acceleration libraries from Microsoft.

 Code can be run as standard ``.py`` file or exploit VS Code to run the code as Jupyter Notebook (https://code.visualstudio.com/docs/python/jupyter-support-py).

### Scripts and tutorial exploited as references

``bert_onnx.py``: check [here](https://github.com/microsoft/onnxruntime/blob/master/onnxruntime/python/tools/transformers/notebooks/PyTorch_Bert-Squad_OnnxRuntime_CPU.ipynb).

``scikit_learn_convert.py``: check [here](http://onnx.ai/sklearn-onnx/).
